{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Lagged', 'MA', 'WMA', 'MA-Lagged', 'WMA-Lagged']\n",
    "\n",
    "def load_datasets():\n",
    "    datasets = dict()\n",
    "    for lb in labels:\n",
    "        new_df = pd.read_excel(f\"River-Data-{lb}.xlsx\")\n",
    "        new_df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "        datasets[lb] = new_df\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "data = load_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for standardising and unstandardising columns\n",
    "def standardise_columns(df, cols):\n",
    "    subset_df = df[cols]\n",
    "    subset_df = 0.8 * ((subset_df - subset_df.min()) / (subset_df.max() - subset_df.min())) + 0.1\n",
    "    return subset_df\n",
    "\n",
    "def unstandardise_columns(df, cols, max_val, min_val):\n",
    "    subset_df = df[cols]\n",
    "    subset_df = ((subset_df - subset_df.min()) / 0.8) * (max_val - min_val) + min_val\n",
    "    return subset_df\n",
    "\n",
    "def standardise_value(x, max_val, min_val):\n",
    "    return 0.8 * ((x - min_val)) / (max_val - min_val) + 0.1\n",
    "\n",
    "def unstandardise_value(x, max_val, min_val):\n",
    "    return ((x - 0.1) / 0.8) * (max_val - min_val) + min_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicAnn:\n",
    "    def __init__(self, layers, max_st_val, min_st_val, activ_func=\"sigmoid\"):\n",
    "        self.layers = layers\n",
    "        self.num_layers = len(layers)\n",
    "        self.max_val = max_st_val\n",
    "        self.min_val = min_st_val\n",
    "        self.activ_func = activ_func\n",
    "        \n",
    "        weight_shapes = [(layers[i-1],layers[i]) for i in range(1, len(layers))]\n",
    "        self.weights = {\n",
    "            f\"W{i+1}\": np.random.standard_normal(s)/s[0]**0.5 \n",
    "            for i, s in enumerate(weight_shapes) \n",
    "        }\n",
    "        self.biases = {\n",
    "            f\"B{i+1}\": np.random.randn(l,1)/l**0.5 \n",
    "            for i, l in enumerate(layers[1:])\n",
    "        }\n",
    "    \n",
    "    def activation(self, x):\n",
    "        if self.activ_func == \"sigmoid\":\n",
    "            return 1/(1+np.exp(-x))\n",
    "        elif self.activ_func == \"tanh\":\n",
    "            return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
    "        elif self.activ_func == \"relu\":\n",
    "            return x * (x > 0)\n",
    "        elif self.activ_func == \"linear\":\n",
    "            return x\n",
    "    \n",
    "    def activation_deriv(self, a):\n",
    "        if self.activ_func == \"sigmoid\":\n",
    "            return a * (1 - a)\n",
    "        elif self.activ_func == \"tanh\":\n",
    "            return 1 - a**2\n",
    "        elif self.activ_func == \"relu\":\n",
    "            return 1 * (a > 0)\n",
    "        elif self.activ_func == \"linear\":\n",
    "            return np.ones(a.shape)\n",
    "    \n",
    "    def train(self, features, targets, epochs=1000, learning_rate=0.1):\n",
    "        results = pd.DataFrame()\n",
    "        real_targets = unstandardise_value(targets, self.max_val, self.min_val)\n",
    "        num_targets = len(targets)\n",
    "        \n",
    "        for _ in range(epochs):\n",
    "            # Forward pass\n",
    "            activations = self.forward_pass(features)\n",
    "\n",
    "            # Error calculation\n",
    "            output_layer = activations[f\"A{self.num_layers - 1}\"]\n",
    "            real_preds = unstandardise_value(output_layer, self.max_val, self.min_val)\n",
    "            results = results.append({\n",
    "                \"mse\": mean_squared_error(real_targets, real_preds),\n",
    "                \"rmse\": mean_squared_error(real_targets, real_preds, squared=False),\n",
    "                \"mae\": mean_absolute_error(real_targets, real_preds),\n",
    "                \"r_sqr\": r2_score(real_targets, real_preds),\n",
    "                \"st_mse\": mean_squared_error(targets, output_layer),\n",
    "                \"st_rmse\": mean_squared_error(targets, output_layer, squared=False),\n",
    "                \"st_mae\": mean_absolute_error(targets, output_layer),\n",
    "                \"st_r_sqr\": r2_score(targets, output_layer)\n",
    "            }, ignore_index=True)\n",
    "\n",
    "            # Backward pass\n",
    "            deltas = self.compute_deltas(activations, targets, output_layer)\n",
    "            self.update_weights(deltas, activations, features, num_targets, learning_rate)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def predict(self, test_inputs, st_actual_outputs):\n",
    "        # Forward pass\n",
    "        activations = self.forward_pass(test_inputs)\n",
    "        st_preds = activations[f\"A{self.num_layers - 1}\"]\n",
    "        \n",
    "        actual_outputs = unstandardise_value(st_actual_outputs, self.max_val, self.min_val)\n",
    "        preds = unstandardise_value(st_preds, self.max_val, self.min_val)\n",
    "        \n",
    "        results = pd.DataFrame(\n",
    "            data={\n",
    "                \"Actual Values\": actual_outputs.flatten(), \n",
    "                \"Predicted Values\": preds.flatten(),\n",
    "                \"Actual Values (Standardised)\": st_actual_outputs.flatten(),\n",
    "                \"Predicted Values (Standardised)\": st_preds.flatten(),\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        results[\"Absolute Error\"] = abs(results[\"Actual Values\"] - results[\"Predicted Values\"])\n",
    "        results[\"Absolute Error (Standardised Values)\"] = abs(results[\"Actual Values (Standardised)\"] - results[\"Predicted Values (Standardised)\"])\n",
    "        \n",
    "        error_metrics = pd.DataFrame(data={\n",
    "            \"mse\": [mean_squared_error(actual_outputs, preds)],\n",
    "            \"rmse\": [mean_squared_error(actual_outputs, preds, squared=False)],\n",
    "            \"mae\": [mean_absolute_error(actual_outputs, preds)],\n",
    "            \"r_sqr\": [r2_score(actual_outputs, preds)],\n",
    "            \"st_mse\": [mean_squared_error(st_actual_outputs, st_preds)],\n",
    "            \"st_rmse\": [mean_squared_error(st_actual_outputs, st_preds, squared=False)],\n",
    "            \"st_mae\": [mean_absolute_error(st_actual_outputs, st_preds)],\n",
    "            \"st_r_sqr\": [r2_score(st_actual_outputs, st_preds)]\n",
    "        })\n",
    "        \n",
    "        return results, error_metrics\n",
    "    \n",
    "    def forward_pass(self, features):\n",
    "        activation = self.activation(np.dot(features, self.weights[\"W1\"]) + self.biases[\"B1\"].T)\n",
    "        activations = {\"A1\": activation}\n",
    "        for i in range(2, self.num_layers):\n",
    "            activation = self.activation(np.dot(activation, self.weights[f\"W{i}\"]) + self.biases[f\"B{i}\"].T)\n",
    "            activations[f\"A{i}\"] = activation\n",
    "        \n",
    "        return activations\n",
    "    \n",
    "    def compute_deltas(self, activations, targets, output_layer):\n",
    "        ## Computing deltas\n",
    "        output_err = targets - output_layer\n",
    "        output_delta = output_err * self.activation_deriv(output_layer)\n",
    "        deltas = {\"dw1\": output_delta}\n",
    "\n",
    "        for i in range(self.num_layers - 1, 1, -1):\n",
    "            dw = deltas[f\"dw{self.num_layers - i}\"]\n",
    "            act = activations[f\"A{i-1}\"]\n",
    "            w = self.weights[f\"W{i}\"]\n",
    "            deltas[f\"dw{self.num_layers - i + 1}\"] = np.dot(dw, w.T) * self.activation_deriv(act)\n",
    "        \n",
    "        return deltas\n",
    "    \n",
    "    def update_weights(self, deltas, activations, features, num_targets, l_rate):\n",
    "        ## Updating weights and biases\n",
    "        delta = deltas[f\"dw{self.num_layers - 1}\"]\n",
    "        self.weights[\"W1\"] += l_rate * (np.dot(features.T, delta)) / num_targets\n",
    "        self.biases[\"B1\"] += l_rate * (np.dot(delta.T, np.ones((num_targets, 1)))) / num_targets\n",
    "\n",
    "        for i in range(2, self.num_layers):\n",
    "            act = activations[f\"A{i-1}\"]\n",
    "            dw = deltas[f\"dw{self.num_layers - i}\"]\n",
    "            self.weights[f\"W{i}\"] += l_rate * (np.dot(act.T, dw)) / num_targets\n",
    "            self.biases[f\"B{i}\"] += l_rate * np.dot(dw.T, np.ones((num_targets, 1))) / num_targets      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build, Train and Test ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test(feature_set, feature_cols, target_cols, layers=(\"auto\", 1), activ_func=\"linear\"):\n",
    "    # Getting standardisation values for targets\n",
    "    min_val = feature_set[target_cols].min()[0]\n",
    "    max_val = feature_set[target_cols].max()[0]\n",
    "    \n",
    "    # Standardising feature set\n",
    "    st_feature_set = standardise_columns(feature_set, feature_set.columns)\n",
    "    features = st_feature_set[feature_cols]\n",
    "    targets = st_feature_set[target_cols]\n",
    "    \n",
    "    # Splitting data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, targets)\n",
    "    \n",
    "    # Building model\n",
    "    if layers[0] == \"auto\":\n",
    "        layers = (len(feature_cols),) + layers[1:]\n",
    "    \n",
    "    ann = BasicAnn(layers, max_val, min_val, activ_func)\n",
    "    \n",
    "    # Training model\n",
    "    training_results = ann.train(X_train.to_numpy(), y_train.to_numpy())\n",
    "    print(training_results)\n",
    "    print(\"Final error metrics:\\n\\n\", training_results.iloc[-1], end=\"\\n\\n\")\n",
    "    training_results.mae.plot()\n",
    "    \n",
    "    # Predicting model\n",
    "    prediction_results = ann.predict(X_test.to_numpy(), y_test.to_numpy())\n",
    "    predictions, error_metrics = prediction_results[0], prediction_results[1]\n",
    "    print(prediction_results)\n",
    "    print(error_metrics)\n",
    "    predictions.plot(y=[\"Actual Values\", \"Predicted Values\"])\n",
    "    \n",
    "    return {\n",
    "        \"training_results\": training_results,\n",
    "        \"predictions\": predictions,\n",
    "        \"error_metrics\": error_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for building custom feature and target sets\n",
    "def build_feature_set(*datasets):\n",
    "    assert len(datasets) > 0, \"No data sets entered\"\n",
    "    datasets = list(datasets)\n",
    "    min_rows = min(d.shape[0] for d in datasets)\n",
    "    \n",
    "    for i, ds in enumerate(datasets):\n",
    "        datasets[i] = ds.truncate(before=ds.shape[0]-min_rows).reset_index()\n",
    "        datasets[i].drop([\"index\"], axis=1, inplace=True)\n",
    "        \n",
    "    merged_df = datasets[0].iloc[:, :2]\n",
    "    for ds in datasets:\n",
    "        merged_df = pd.concat([merged_df, ds.iloc[:, 2:]], axis=1)\n",
    "    \n",
    "    merged_cols = list(merged_df.columns)\n",
    "    selected_cols = []\n",
    "    \n",
    "    for i in range(0, len(merged_cols), 2):\n",
    "        format_str = f\"{i+1}) {merged_cols[i]}\"\n",
    "        if i != len(merged_cols) - 1:\n",
    "            second_part = f\"{i+2}) {merged_cols[i+1]}\"\n",
    "            num_spaces = 50 - len(format_str)\n",
    "            format_str += num_spaces*\" \" + second_part\n",
    "        print(format_str)\n",
    "    \n",
    "    selected_indices = input(\"\\nSelect columns: \")\n",
    "    for index in selected_indices.split(\",\"):\n",
    "        if \"-\" in index:\n",
    "            first_i, second_i = index.split(\"-\")\n",
    "            selected_cols += merged_cols[int(first_i) - 1: int(second_i)]\n",
    "        else:\n",
    "            selected_cols.append(merged_cols[int(index) - 1])\n",
    "    \n",
    "    return merged_df[selected_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations Between Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for plotting a correlation heatmap of a given feature set\n",
    "def plot_correlation_matrix(corr_data, title, figsize=(16,6), mask=False):\n",
    "    if mask:\n",
    "        mask = np.triu(np.ones_like(corr_data, dtype=bool))\n",
    "    plt.figure(figsize=figsize, dpi=500)\n",
    "    heatmap = sns.heatmap(corr_data, vmin=-1, vmax=1, annot=True, mask=mask)\n",
    "    heatmap.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Date                                           2) Skelton MDF (Cumecs)\n",
      "3) Crakehill MDF (t-1)                            4) Skip Bridge MDF (t-1)\n",
      "5) Westwick MDF (t-1)                             6) Skelton MDF (t-1)\n",
      "7) Crakehill MDF (t-2)                            8) Skip Bridge MDF (t-2)\n",
      "9) Westwick MDF (t-2)                             10) Skelton MDF (t-2)\n",
      "11) Crakehill MDF (t-3)                           12) Skip Bridge MDF (t-3)\n",
      "13) Westwick MDF (t-3)                            14) Skelton MDF (t-3)\n",
      "15) Arkengarthdale DRT (t-1)                      16) East Cowton DRT (t-1)\n",
      "17) Malham Tarn DRT (t-1)                         18) Snaizeholme DRT (t-1)\n",
      "19) Arkengarthdale DRT (t-2)                      20) East Cowton DRT (t-2)\n",
      "21) Malham Tarn DRT (t-2)                         22) Snaizeholme DRT (t-2)\n",
      "23) Arkengarthdale DRT (t-3)                      24) East Cowton DRT (t-3)\n",
      "25) Malham Tarn DRT (t-3)                         26) Snaizeholme DRT (t-3)\n",
      "\n",
      "Select columns: 2,3-6,15-26\n"
     ]
    }
   ],
   "source": [
    "# fs = build_feature_set(data['WMA-Lagged'], data['WMA'], data['Lagged'], data['MA'], data['MA-Lagged'])\n",
    "fs = build_feature_set(data['Lagged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skelton MDF (Cumecs)</th>\n",
       "      <th>Crakehill MDF (t-1)</th>\n",
       "      <th>Skip Bridge MDF (t-1)</th>\n",
       "      <th>Westwick MDF (t-1)</th>\n",
       "      <th>Skelton MDF (t-1)</th>\n",
       "      <th>Arkengarthdale DRT (t-1)</th>\n",
       "      <th>East Cowton DRT (t-1)</th>\n",
       "      <th>Malham Tarn DRT (t-1)</th>\n",
       "      <th>Snaizeholme DRT (t-1)</th>\n",
       "      <th>Arkengarthdale DRT (t-2)</th>\n",
       "      <th>East Cowton DRT (t-2)</th>\n",
       "      <th>Malham Tarn DRT (t-2)</th>\n",
       "      <th>Snaizeholme DRT (t-2)</th>\n",
       "      <th>Arkengarthdale DRT (t-3)</th>\n",
       "      <th>East Cowton DRT (t-3)</th>\n",
       "      <th>Malham Tarn DRT (t-3)</th>\n",
       "      <th>Snaizeholme DRT (t-3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.47</td>\n",
       "      <td>9.46</td>\n",
       "      <td>4.124</td>\n",
       "      <td>8.057</td>\n",
       "      <td>23.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.70</td>\n",
       "      <td>9.41</td>\n",
       "      <td>4.363</td>\n",
       "      <td>7.925</td>\n",
       "      <td>23.47</td>\n",
       "      <td>2.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.01</td>\n",
       "      <td>26.30</td>\n",
       "      <td>11.962</td>\n",
       "      <td>58.704</td>\n",
       "      <td>60.70</td>\n",
       "      <td>11.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>111.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.99</td>\n",
       "      <td>32.10</td>\n",
       "      <td>10.237</td>\n",
       "      <td>34.416</td>\n",
       "      <td>98.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>111.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>61.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.66</td>\n",
       "      <td>19.30</td>\n",
       "      <td>7.254</td>\n",
       "      <td>22.263</td>\n",
       "      <td>56.99</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>111.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>29.52</td>\n",
       "      <td>11.70</td>\n",
       "      <td>6.075</td>\n",
       "      <td>12.671</td>\n",
       "      <td>33.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>28.67</td>\n",
       "      <td>10.90</td>\n",
       "      <td>5.721</td>\n",
       "      <td>11.558</td>\n",
       "      <td>29.52</td>\n",
       "      <td>1.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>29.31</td>\n",
       "      <td>11.10</td>\n",
       "      <td>5.486</td>\n",
       "      <td>11.411</td>\n",
       "      <td>28.67</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>34.28</td>\n",
       "      <td>12.10</td>\n",
       "      <td>5.329</td>\n",
       "      <td>11.781</td>\n",
       "      <td>29.31</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>39.42</td>\n",
       "      <td>15.80</td>\n",
       "      <td>6.177</td>\n",
       "      <td>14.255</td>\n",
       "      <td>34.28</td>\n",
       "      <td>12.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1448 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Skelton MDF (Cumecs)  Crakehill MDF (t-1)  Skip Bridge MDF (t-1)  \\\n",
       "0                    23.47                 9.46                  4.124   \n",
       "1                    60.70                 9.41                  4.363   \n",
       "2                    98.01                26.30                 11.962   \n",
       "3                    56.99                32.10                 10.237   \n",
       "4                    56.66                19.30                  7.254   \n",
       "...                    ...                  ...                    ...   \n",
       "1443                 29.52                11.70                  6.075   \n",
       "1444                 28.67                10.90                  5.721   \n",
       "1445                 29.31                11.10                  5.486   \n",
       "1446                 34.28                12.10                  5.329   \n",
       "1447                 39.42                15.80                  6.177   \n",
       "\n",
       "      Westwick MDF (t-1)  Skelton MDF (t-1)  Arkengarthdale DRT (t-1)  \\\n",
       "0                  8.057              23.60                       0.0   \n",
       "1                  7.925              23.47                       2.4   \n",
       "2                 58.704              60.70                      11.2   \n",
       "3                 34.416              98.01                       0.0   \n",
       "4                 22.263              56.99                       5.6   \n",
       "...                  ...                ...                       ...   \n",
       "1443              12.671              33.06                       0.0   \n",
       "1444              11.558              29.52                       1.6   \n",
       "1445              11.411              28.67                      11.2   \n",
       "1446              11.781              29.31                       3.2   \n",
       "1447              14.255              34.28                      12.8   \n",
       "\n",
       "      East Cowton DRT (t-1)  Malham Tarn DRT (t-1)  Snaizeholme DRT (t-1)  \\\n",
       "0                       0.0                    0.8                    0.0   \n",
       "1                      24.8                    0.8                   61.6   \n",
       "2                       5.6                   33.6                  111.2   \n",
       "3                       0.0                    1.6                    0.8   \n",
       "4                       4.0                   17.6                   36.0   \n",
       "...                     ...                    ...                    ...   \n",
       "1443                    0.8                    0.0                    0.0   \n",
       "1444                   14.4                    8.8                    3.2   \n",
       "1445                   11.2                    4.8                    4.8   \n",
       "1446                    4.8                    0.0                    0.8   \n",
       "1447                    6.4                    5.6                    4.0   \n",
       "\n",
       "      Arkengarthdale DRT (t-2)  East Cowton DRT (t-2)  Malham Tarn DRT (t-2)  \\\n",
       "0                          0.0                    0.0                    0.8   \n",
       "1                          0.0                    0.0                    0.8   \n",
       "2                          2.4                   24.8                    0.8   \n",
       "3                         11.2                    5.6                   33.6   \n",
       "4                          0.0                    0.0                    1.6   \n",
       "...                        ...                    ...                    ...   \n",
       "1443                       0.0                    3.2                    0.8   \n",
       "1444                       0.0                    0.8                    0.0   \n",
       "1445                       1.6                   14.4                    8.8   \n",
       "1446                      11.2                   11.2                    4.8   \n",
       "1447                       3.2                    4.8                    0.0   \n",
       "\n",
       "      Snaizeholme DRT (t-2)  Arkengarthdale DRT (t-3)  East Cowton DRT (t-3)  \\\n",
       "0                       0.0                       0.0                    0.0   \n",
       "1                       0.0                       0.0                    0.0   \n",
       "2                      61.6                       0.0                    0.0   \n",
       "3                     111.2                       2.4                   24.8   \n",
       "4                       0.8                      11.2                    5.6   \n",
       "...                     ...                       ...                    ...   \n",
       "1443                    1.6                       0.0                    0.0   \n",
       "1444                    0.0                       0.0                    3.2   \n",
       "1445                    3.2                       0.0                    0.8   \n",
       "1446                    4.8                       1.6                   14.4   \n",
       "1447                    0.8                      11.2                   11.2   \n",
       "\n",
       "      Malham Tarn DRT (t-3)  Snaizeholme DRT (t-3)  \n",
       "0                       0.0                    4.0  \n",
       "1                       0.8                    0.0  \n",
       "2                       0.8                    0.0  \n",
       "3                       0.8                   61.6  \n",
       "4                      33.6                  111.2  \n",
       "...                     ...                    ...  \n",
       "1443                    0.0                    0.0  \n",
       "1444                    0.8                    1.6  \n",
       "1445                    0.0                    0.0  \n",
       "1446                    8.8                    3.2  \n",
       "1447                    4.8                    4.8  \n",
       "\n",
       "[1448 rows x 17 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiLayerAnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-30cfb0b3f9af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeature_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbuild_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactiv_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-9ead88599ac7>\u001b[0m in \u001b[0;36mbuild_train_test\u001b[0;34m(feature_set, feature_cols, target_cols, layers, activ_func)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiLayerAnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactiv_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Training model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MultiLayerAnn' is not defined"
     ]
    }
   ],
   "source": [
    "target_cols = [fs.columns[0]]\n",
    "feature_cols = list(fs.columns[1:])\n",
    "\n",
    "build_train_test(fs, feature_cols, target_cols, layers=(\"auto\", 3, 1), activ_func=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
